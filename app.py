# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KJTztppfl1nLtxhWxaddWpEoUqkPoQRk
"""

from huggingface_hub import InferenceClient
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import os
import time
import feedparser
from openai import OpenAI
import sys
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from fastapi.responses import FileResponse


app = FastAPI()

# ✅ Serve static frontend (HTML UI)
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def serve_ui():
    return FileResponse("static/index.html")
# ✅ OpenAI Client Initialization
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def update_articles_file():
    feed_url = f"https://medium.com/feed/@sentivity.ai"
    feed = feedparser.parse(feed_url)
    
    if not feed.entries:
        print("No articles found or couldn't fetch feed")
        return False
    
    latest = feed.entries[0]
    new_article = f"{latest.published.split('T')[0]} - {latest.title} - {latest.link}\n"
    articles_path = "articles.txt"
    
    existing_content = ""
    if os.path.exists(articles_path):
        with open(articles_path, "r", encoding="utf-8") as f:
            existing_content = f.read()
        if new_article.strip() in existing_content:
            print("Latest article already in file")
            return False
    
    with open(articles_path, "w", encoding="utf-8") as f:
        f.write(new_article + existing_content)
    print(f"Added new article: {latest.title}")
    return True

# Load base context
base_content_path = "base_content.txt"
try:
    with open(base_content_path, "r", encoding="utf-8") as f:
        base_content = f.read()
    print("Successfully loaded base_content.txt")
except FileNotFoundError:
    base_content = "No base content found."
    print("Warning: base_content.txt not found.")

# Load articles
articles_file_path = "articles.txt"
try:
    with open(articles_file_path, "r", encoding="utf-8") as f:
        articles_content = f.read()
    print("Successfully loaded articles.txt")
except FileNotFoundError:
    articles_content = "No article content found."
    print("Warning: articles.txt not found.")

# Vectorizer setup
article_chunks = [chunk.strip() for chunk in articles_content.split("\n\n") if chunk.strip()]
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(article_chunks)
print("TF-IDF matrix shape:", tfidf_matrix.shape)

def retrieve_relevant_chunks(query, top_k=3):
    query_vec = vectorizer.transform([query])
    similarities = cosine_similarity(query_vec, tfidf_matrix)
    top_indices = np.argsort(similarities[0])[::-1][:top_k]
    retrieved = [article_chunks[i] for i in top_indices if i < len(article_chunks)]
    return "\n\n".join(retrieved)

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat_endpoint(data: ChatRequest):
    message = data.message
    print("📥 Incoming message:", message)

    max_tokens = 512
    temperature = 0.7
    top_p = 0.95

    try:
        # Retrieve article context
        retrieved_context = retrieve_relevant_chunks(message)
        full_system_message = (
            "You are Ivy, Sentivity.ai’s official chatbot. "
            "WHEN ASKED ABOUT NEWS that means Hive. "
            "You must ONLY discuss Sentivity.ai’s products, research, methodologies, and published insights. "
            "You CAN answer questions about sentiment trends, market events, or political topics IF they are reported in Sentivity.ai content. "
            "If the user asks a vague question (e.g., 'anything happen on April 18th?' or 'latest Hive headlines?'), check if Sentivity.ai has a relevant article and return a structured summary. "
            "Do NOT speculate, do NOT refer to outside sources, and do NOT comment on events not covered by Sentivity.ai. "
            "If the user asks about unrelated topics, politely redirect them to Sentivity.ai’s website or Medium page. "
            "Keep your tone helpful, clear, and professional. Use bullet points or numbered lists for headline summaries when appropriate.\n\n"
            + base_content
            + "\n\nRetrieved Articles Content:\n"
            + retrieved_context
            + "\n\nYou are a friendly chatbot, but you must only discuss Sentivity.ai products and official insights."
        )

        messages = [
            {"role": "system", "content": full_system_message},
            {"role": "user", "content": message}
        ]

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
        )

        content = response.choices[0].message.content.strip() 
        print("📤 Ivy’s response:", content)
        return {"response": content or "⚠️ Ivy had no response."}

    except Exception as e:
        print("❌ Error occurred:", str(e))
        return {"error": str(e)}
